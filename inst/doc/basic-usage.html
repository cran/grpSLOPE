<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Alexej Gossmann" />

<meta name="date" content="2025-06-29" />

<title>Basic usage of grpSLOPE</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Basic usage of grpSLOPE</h1>
<h4 class="author">Alexej Gossmann</h4>
<h4 class="date">2025-06-29</h4>



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Group SLOPE (<em>gSLOPE</em>) is a penalized linear regression method
that is used for adaptive selection of groups of significant predictors
in a high-dimensional linear model. A unique property of the Group SLOPE
method is that it offers group false discovery rate (<em>gFDR</em>)
control (i.e., control of the expected proportion of irrelevant groups
among the total number of groups selected by Group SLOPE). A detailed
description of the method can be found in <a href="https://arxiv.org/abs/1610.04960">D. Brzyski, A. Gossmann, W. Su,
and M. Bogdan (2016) <em>Group SLOPE — adaptive selection of groups of
predictors</em></a>.</p>
<p>Group SLOPE is implemented in the R package <code>grpSLOPE</code>. As
an introduction to the R package, in the following we will walk through
a basic usage demonstration. First, we will simulate some data, before
we feed it into <code>grpSLOPE</code>, and subsequently examine the
output.</p>
</div>
<div id="data-generation" class="section level2">
<h2>Data generation</h2>
<p>We simulate a <span class="math inline">\(500 \times 500\)</span>
SNP-data-like model matrix.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">17082016</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>p     <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>probs <span class="ot">&lt;-</span> <span class="fu">runif</span>(p, <span class="fl">0.1</span>, <span class="fl">0.5</span>)</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>probs <span class="ot">&lt;-</span> <span class="fu">t</span>(probs) <span class="sc">%x%</span> <span class="fu">matrix</span>(<span class="dv">1</span>,p,<span class="dv">2</span>)</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>X0    <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rbinom</span>(<span class="dv">2</span><span class="sc">*</span>p<span class="sc">*</span>p, <span class="dv">1</span>, probs), p, <span class="dv">2</span><span class="sc">*</span>p)</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>X     <span class="ot">&lt;-</span> X0 <span class="sc">%*%</span> (<span class="fu">diag</span>(p) <span class="sc">%x%</span> <span class="fu">matrix</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>))</span></code></pre></div>
<p>For example, the upper left <span class="math inline">\(10 \times
10\)</span> corner of <span class="math inline">\(X\)</span> looks as
follows.</p>
<table style="width:56%;">
<colgroup>
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">2</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">2</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p><strong>Note:</strong> In fact, with the default settings, the Group
SLOPE method is guaranteed to control gFDR only when applied to a data
matrix, where the columns corresponding to different groups of
predictors are nearly uncorrelated. The relevant theoretical results can
be found in <a href="https://arxiv.org/abs/1610.04960">Brzyski et.
al. (2016)</a>. Only for the brevity of exposition we neither check for
nor enforce low between-group correlations in this example.</p>
<p>We divide the 500 predictor variables into 100 groups of sizes
ranging from 3 to 7.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>group <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, <span class="at">each=</span><span class="dv">3</span>),</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>           <span class="fu">rep</span>(<span class="dv">21</span><span class="sc">:</span><span class="dv">40</span>, <span class="at">each=</span><span class="dv">4</span>),</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>           <span class="fu">rep</span>(<span class="dv">41</span><span class="sc">:</span><span class="dv">60</span>, <span class="at">each=</span><span class="dv">5</span>),</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>           <span class="fu">rep</span>(<span class="dv">61</span><span class="sc">:</span><span class="dv">80</span>, <span class="at">each=</span><span class="dv">6</span>),</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>           <span class="fu">rep</span>(<span class="dv">81</span><span class="sc">:</span><span class="dv">100</span>, <span class="at">each=</span><span class="dv">7</span>))</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>group <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;grp&quot;</span>, group)</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="fu">str</span>(group)</span></code></pre></div>
<pre><code>##  chr [1:500] &quot;grp1&quot; &quot;grp1&quot; &quot;grp1&quot; &quot;grp2&quot; &quot;grp2&quot; &quot;grp2&quot; &quot;grp3&quot; &quot;grp3&quot; &quot;grp3&quot; ...</code></pre>
<p>For further usage we keep additional information about the grouping
structure of predictors, such as the total number of groups and the
group sizes.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># this generates a list containing a vector of indices for each group:</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>group.id <span class="ot">&lt;-</span> grpSLOPE<span class="sc">::</span><span class="fu">getGroupID</span>(group)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co"># this extracts the total number of groups:</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>n.group <span class="ot">&lt;-</span> <span class="fu">length</span>(group.id)</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co"># this vector collects the sizes of every group of predictors:</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>group.length <span class="ot">&lt;-</span> <span class="fu">sapply</span>(group.id, <span class="at">FUN=</span>length)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a><span class="co"># this vector collects the group names:</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>group.names <span class="ot">&lt;-</span> <span class="fu">names</span>(group.id)</span></code></pre></div>
<p>In order to simulate a response variable, we randomly select 10
groups to be truly significant.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>ind.relevant <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n.group, <span class="dv">10</span>)) <span class="co"># indices of relevant groups</span></span></code></pre></div>
<p>The randomly selected truly significant groups are:</p>
<table style="width:100%;">
<colgroup>
<col width="8%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">grp4</td>
<td align="center">grp12</td>
<td align="center">grp25</td>
<td align="center">grp34</td>
<td align="center">grp35</td>
<td align="center">grp38</td>
<td align="center">grp66</td>
<td align="center">grp67</td>
<td align="center">grp81</td>
<td align="center">grp89</td>
</tr>
</tbody>
</table>
<p>Then we generate the vector of regression coefficients, by sampling
effect sizes for the significant groups from the Uniform(0,1)
distribution.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, p)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> ind.relevant) {</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>  b[group.id[[j]]] <span class="ot">&lt;-</span> <span class="fu">runif</span>(group.length[j])</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>}</span></code></pre></div>
<p>Finally, we generate the response vector according to a linear model
with i.i.d. <span class="math inline">\(\mathcal{N}(0, 1)\)</span> noise
terms.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> b <span class="sc">+</span> <span class="fu">rnorm</span>(p)</span></code></pre></div>
</div>
<div id="fitting-the-group-slope-model" class="section level2">
<h2>Fitting the Group SLOPE model</h2>
<p>We fit the Group SLOPE model to the simulated data. The function
argument <code>fdr</code> signifies the target group-wise false
discovery rate (gFDR) of the variable selection procedure.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="fu">library</span>(grpSLOPE)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">grpSLOPE</span>(<span class="at">X=</span>X, <span class="at">y=</span>y, <span class="at">group=</span>group, <span class="at">fdr=</span><span class="fl">0.1</span>)</span></code></pre></div>
</div>
<div id="model-fit-results" class="section level2">
<h2>Model fit results</h2>
<p>The resulting object <code>model</code> of class “grpSLOPE” contains
a lot of information about the resulting Group SLOPE model. Some of
these parameters are shown below.</p>
<ul>
<li><p>Groups that were selected as significant by the Group SLOPE
method.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>model<span class="sc">$</span>selected</span></code></pre></div>
<pre><code>##  [1] &quot;grp4&quot;  &quot;grp12&quot; &quot;grp20&quot; &quot;grp25&quot; &quot;grp34&quot; &quot;grp35&quot; &quot;grp38&quot; &quot;grp64&quot; &quot;grp65&quot;
## [10] &quot;grp66&quot; &quot;grp67&quot; &quot;grp81&quot; &quot;grp89&quot;</code></pre>
<p>Notice that the model has correctly identified all significant
groups, and additionally has falsely reported the group “grp11” as
significant.</p></li>
<li><p>The estimated noise level <span class="math inline">\(\hat{\sigma}\)</span> (true <span class="math inline">\(\sigma\)</span> is equal to one).</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">sigma</span>(model) <span class="co"># or equivalently: model$sigma</span></span></code></pre></div>
<pre><code>## [1] 0.9529587</code></pre></li>
<li><p>The regression coefficients, which can be displayed either on the
normalized scale (i.e., the scale corresponding to the normalized
versions of <span class="math inline">\(X\)</span> and <span class="math inline">\(y\)</span>, on which all the parameter estimates
are computed internally),</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># the first 13 coefficient estimates</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="fu">coef</span>(model)[<span class="dv">1</span><span class="sc">:</span><span class="dv">13</span>]</span></code></pre></div>
<pre><code>##   grp1_1   grp1_2   grp1_3   grp2_1   grp2_2   grp2_3   grp3_1   grp3_2 
## 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 
##   grp3_3   grp4_1   grp4_2   grp4_3   grp5_1 
## 0.000000 2.418774 9.119495 6.620014 0.000000</code></pre>
<p>or on the original scale of <span class="math inline">\(X\)</span>
and <span class="math inline">\(y\)</span>,</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># intercept and the first 13 coefficient estimates</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="fu">coef</span>(model, <span class="at">scaled =</span> <span class="cn">FALSE</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">14</span>]</span></code></pre></div>
<pre><code>## (Intercept)      grp1_1      grp1_2      grp1_3      grp2_1      grp2_2 
##   3.5794874   0.0000000   0.0000000   0.0000000   0.0000000   0.0000000 
##      grp2_3      grp3_1      grp3_2      grp3_3      grp4_1      grp4_2 
##   0.0000000   0.0000000   0.0000000   0.0000000   0.1598203   0.5656019 
##      grp4_3      grp5_1 
##   0.5158554   0.0000000</code></pre>
<p>(notice that the coefficients are named corresponding to the given
grouping structure). As expected from a penalized regression method, we
observe some shrinkage, when we compare the above to the true
parameters.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co"># true first 13 coefficients</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>b[<span class="dv">1</span><span class="sc">:</span><span class="dv">13</span>]</span></code></pre></div>
<pre><code>##  [1] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
##  [8] 0.0000000 0.0000000 0.1713692 0.6425599 0.6218365 0.0000000</code></pre></li>
<li><p>It might also be interesting to plot the first few elements of
the regularizing sequence <span class="math inline">\(\lambda\)</span>
used by the Group SLOPE method for the given inputs.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="fu">plot</span>(model<span class="sc">$</span>lambda[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>], <span class="at">xlab =</span> <span class="st">&quot;Index&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Lambda&quot;</span>, <span class="at">type=</span><span class="st">&quot;l&quot;</span>)</span></code></pre></div>
<p><img role="img" src="data:image/png;base64,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" /><!-- --></p></li>
</ul>
<p>We can further check the performance of the method by computing the
resulting group false discovery proportion (gFDP) and power.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>true.relevant <span class="ot">&lt;-</span> group.names[ind.relevant]</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>truepos       <span class="ot">&lt;-</span> <span class="fu">intersect</span>(model<span class="sc">$</span>selected, true.relevant)</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>n.truepos  <span class="ot">&lt;-</span> <span class="fu">length</span>(truepos)</span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>n.selected <span class="ot">&lt;-</span> <span class="fu">length</span>(model<span class="sc">$</span>selected)</span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>n.falsepos <span class="ot">&lt;-</span> n.selected <span class="sc">-</span> n.truepos</span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a>gFDP <span class="ot">&lt;-</span> n.falsepos <span class="sc">/</span> <span class="fu">max</span>(<span class="dv">1</span>, n.selected)</span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a>pow <span class="ot">&lt;-</span> n.truepos <span class="sc">/</span> <span class="fu">length</span>(true.relevant)</span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;gFDP =&quot;</span>, gFDP))</span></code></pre></div>
<p>[1] “gFDP = 0.230769230769231”</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Power =&quot;</span>, pow))</span></code></pre></div>
<p>[1] “Power = 1”</p>
<p>We see that the method indeed did not exceed the target gFDR, while
maintaining a high power.</p>
</div>
<div id="lambda-sequences" class="section level2">
<h2>Lambda sequences</h2>
<p>Multiple ways to select the regularizing sequence <span class="math inline">\(\lambda\)</span> are available.</p>
<p>If a group structure with little correlation between groups can be
assumed (i.e., groups in the standardized model matrix are nearly
orthogonal), then we suggest to use the sequence “corrected”, which is
the default.</p>
<p>The <span class="math inline">\(\lambda\)</span> sequences “mean” and
“max” can be used together with the options
<code>orthogonalize = FALSE</code> and <code>normalize = FALSE</code>,
when the columns of the model matrix are exactly orthogonal to each
other (“max” is more conservative, giving exact gFDR control only when
all groups have the same size, and otherwise resulting in a lower gFDR
than the target level).</p>
<p>Alternatively, any non-increasing sequence of appropriate length can
be utilized. However, we do not recommend to use any other <span class="math inline">\(\lambda\)</span> sequences unless you really know
what you are doing.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/1407.3824v2">Bogdan, M., van den
Berg, E., Sabatti, C., Su, W., and Candès, E. J. (2015). <em>SLOPE —
Adaptive Variable Selection via Convex Optimization.</em></a> The Annals
of Applied Statistics, vol. 9, no. 3, p. 1103.</p></li>
<li><p><a href="https://arxiv.org/abs/1610.04960">Brzyski, D., Gossmann,
A., Su, W., and Bogdan, M. (2016). <em>Group SLOPE — adaptive selection
of groups of predictors</em></a> (under review).</p></li>
<li><p><a href="http://dx.doi.org/10.1145/2808719.2808743">Gossmann, A.,
Cao, S., and Wang, Y.-P. (2015). <em>Identification of Significant
Genetic Variants via SLOPE, and Its Extension to Group SLOPE.</em></a>
In Proceedings of the 6th ACM Conference on Bioinformatics,
Computational Biology and Health Informatics, BCB ’15 (pp. 232–240). New
York, NY, USA: ACM.</p></li>
</ul>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
